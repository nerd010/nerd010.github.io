[{"categories":["Apple"],"content":"SwiftUI","date":"2023-06-29","objectID":"/%E5%98%BFswiftui00/","tags":["iOS","SwiftUI"],"title":"嘿SwiftUI00","uri":"/%E5%98%BFswiftui00/"},{"categories":["Apple"],"content":"嘿，SwiftUI 这两周在用 SwiftUI 写一个简单的应用，想着应该可以上架。鉴于 2018 年时莫名其妙开发者账号被封，这次还是放平心态。查了一下，如果过不了身份认证这一步钱也不用交，想想也挺好。 在 SwiftUI 之前我没有在项目中写过声明式的 UI 代码，RN 没有写过，接触过用它写的项目，不过自己当时对非原生的没什么兴趣，后来就让厦门的同事去搞了。Flutter 我距离它最近的一次是前公司同事让我帮他找个人用 Flutter 写 iOS。Weex？嗯…… ","date":"2023-06-29","objectID":"/%E5%98%BFswiftui00/:0:0","tags":["iOS","SwiftUI"],"title":"嘿SwiftUI00","uri":"/%E5%98%BFswiftui00/"},{"categories":["Apple"],"content":"Learning by doing 想好了要做什么就开始创建项目写代码吧。在 2021 年写过一份 demo 的代码也已经完全不记得了。打开苹果官网，打开 SwiftUI Apprentice 这本书的电子版，浏览器可以正常上网。当然现在还有了个新工具—— ChatGPT。有了这些就可以开工了。遇到不会的就查，不知道应该怎么查的就问 ChatGPT，在一个自己相对陌生的领域它的作用还是比较大的。准备个空白文档，随时写下一些自己遇到的问题和查到的有用的解决方法。 ","date":"2023-06-29","objectID":"/%E5%98%BFswiftui00/:1:0","tags":["iOS","SwiftUI"],"title":"嘿SwiftUI00","uri":"/%E5%98%BFswiftui00/"},{"categories":["Apple"],"content":"三种布局方式 HStack， VStack 和 ZStack， 知道了这三种布局方式是不是感觉很简单，确实很简单有手就能写。视图之间要保持距离要怎么写? .padding。还有啥？还有 Spacer()。俩有啥区别？下回再说。我想在视图之间加个分隔线要怎么写? Divider()。普通文本可以直接用 Text()，图片还是 Image()。常用的视图组件与 UIKit 中的几乎都是一样的，只要之前写过 Swift 或者 ObjC 那就没有什么大问题。 想要配置什么属性直接使用 . 语法 Xcode 就会给出提示，不给提示你又不知道的就先问一下 ChatGPT，Google 也是不错的选择。其实到这里，在不好好学习 SwiftUI 的情况下很多简单的 UI 就可以写了。 我们知道 ObjC 或者 Swift 的项目大多都是 MVC 架构的，但是 SwiftUI 的自然架构是 MVVM 。为什么呢？这是个好问题，应该可以单开一篇来写。说回来，不管是 MVC 还是 MVVM，有了 UI 还要有数据才行。 ","date":"2023-06-29","objectID":"/%E5%98%BFswiftui00/:1:1","tags":["iOS","SwiftUI"],"title":"嘿SwiftUI00","uri":"/%E5%98%BFswiftui00/"},{"categories":["Apple"],"content":"数据交互方式 这个问题在写之前我没觉得一定是个难点，在写的过程中发现没那么简单。现在只写下我目前了解的。 SwiftUI 采用属性包装器来实现数据与 UI 的交互。其中分为两大类：值类型和引用类型 值类型：我们常用的内置类型 Int， Bool 和 String 等，还有自定义类型 Structure 和 Enum。这些可以使用 @State， @Binding 和 @Environment 引用类型：SwiftUI 中的引用类型就是 Class 了。ObservableObject, @StateObject, @ObservedObject and @EnvironmentObject. 那这些分别代表什么意思，在什么情况下应该使用哪一个? 这也是个好问题，我们单开一篇。可以先提一个点： 当你需要共享的数据是可改变的状态时，类更适合。当你需要多个独立的状态时，结构更适合。 既然学习的时候要保持一个空杯心态，那我们就先不按使用 UIKit 时的传值方式思考。我们先理解 SwiftUI 的传值方式是怎么实现的。可以单开一篇。 ","date":"2023-06-29","objectID":"/%E5%98%BFswiftui00/:1:2","tags":["iOS","SwiftUI"],"title":"嘿SwiftUI00","uri":"/%E5%98%BFswiftui00/"},{"categories":["Apple"],"content":"数据的持久化 使用数据库 使用 plist 使用 UserDefault 先写到这，学多一点再写。 提外话：看到 CSDN 和 51CTO 的文章还能看到文章的发布时间，还不错。为什么简书和知乎网页版本的文章已经看不到发布或更新的日期呢？ ","date":"2023-06-29","objectID":"/%E5%98%BFswiftui00/:1:3","tags":["iOS","SwiftUI"],"title":"嘿SwiftUI00","uri":"/%E5%98%BFswiftui00/"},{"categories":["Apple"],"content":"shortcuts","date":"2021-12-08","objectID":"/iphone6s%E5%86%8D%E4%B8%80%E6%98%A5/","tags":["iOS","shortcuts"],"title":"iPhone6s再一春","uri":"/iphone6s%E5%86%8D%E4%B8%80%E6%98%A5/"},{"categories":["Apple"],"content":"我这两天利用碎片时间和晚上睡前的时间把我手中的神机 iPhone 6s 利用 Shortcuts 修改了一下功能。也许已经有很多人使用过 Shortcuts 了。但这对我来说是第一次半深度使用。之所以说半深度是因为现在还没有尝试运行脚本，如果加上 Run Script 的话会再上 100% 的可用性吧 我尝试在桌面上只保留小组件，下方保留四个应用。如下图 为了保证效率每个位置的小组件叠加不超过两个 功能分为 读：阅读类的应用 写：主要是笔记类的应用 听：音乐与播客 查：浏览器，词典，地图等几个应用 说与看：社交类应用，微信被单独拿出来放在下面的 Dock 里，这个“小而美”的存在还是要突显一下的 系统相关：设置，应用商店，计算器，日历等，这几个随着使用频率来做调整 联系人：微信几个常联系的人，通过 shortcuts 来发送消息。 最上面：天气，空气质量等 读与写叠加在一起，听与联系人叠加在一起，查与系统相关叠加在一起，社交单独一个放在右下角。下面的 Dock 放了 4 个应用，分别是：电话，微信，图库和相机 shortcuts 刚出来时，不太会用，也不太理解这个东西优秀在哪里，看别人用的很好，但当时我不懂。之后会用它打开应用了！最近又再一次接触到了是在早上起床后，想让它自动播放喜欢的播客，就在 B 站上看到别人做的 shortcut, 这一次竟然看懂了！搞起来！学会在设置变量。 因为有在读英文的技术书箱，还是会遇到一些不认识的词，就想查完后可以记下来，记得之前在 少数派 看到一篇文章讲到使用 shortcut 把单词翻译后记录在 Airtable 里方便复习。因为现在没有用 Airtable， 我是通过 shortcuts 直接存在 notes 上了, 有时间可以再优化。 再一次尝试，想把随时产生的一些想法记下来。因为一直在用 Notion，而 Notion API 也已经足够做这件事了，在网上找到资料，通过 shortcut 把要记录的内容写下，会在本地存一份，然后再通过发送到 Notion。 我目前的使用 shortcuts 的感受是 第一阶段：会使用 shortcuts 打开应用 第二阶段：会使用 shortcuts 设置变量 第三阶段：会使用 shortcuts 配合其它应用的 API 文档来联网做事 第四阶段：在使用 shortcuts 时，需要使用脚本（Script）时，会写 现在我还没有写过脚本。在下次有需要时继续尝试。 ","date":"2021-12-08","objectID":"/iphone6s%E5%86%8D%E4%B8%80%E6%98%A5/:0:0","tags":["iOS","shortcuts"],"title":"iPhone6s再一春","uri":"/iphone6s%E5%86%8D%E4%B8%80%E6%98%A5/"},{"categories":["Apple"],"content":"备注 Shortcuts： 捷径 ","date":"2021-12-08","objectID":"/iphone6s%E5%86%8D%E4%B8%80%E6%98%A5/:1:0","tags":["iOS","shortcuts"],"title":"iPhone6s再一春","uri":"/iphone6s%E5%86%8D%E4%B8%80%E6%98%A5/"},{"categories":null,"content":"关于网站 个人博客，欢迎交流 ","date":"2021-11-01","objectID":"/about/:1:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"关于作者 👨🏻‍💻在成为一名“全站工程师”的路上，渐行渐远～ 📱喜欢小而美的产品 🤪强迫症与拖延症患者 ⏳最近对宇宙，意识，计算机，人工智能有兴趣 🔋爱好摄影，探险 ","date":"2021-11-01","objectID":"/about/:2:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"关于版权 本站所有的原创文章均受 创作共享 署名-非商业性 4.0 许可协议 / CC BY-NC 4.0 保护。 版权说明 任何个人及媒体在转载本站原创内容（包含文字、自制图像、摄影作品）时请遵守以下版权要求: 注明转载 注明来源为本站链接，或转载内容所在的完整网址 本站图片，除原创作品之外，多数来自互联网。 此类图片的原版权所有者可在任何时候、以任何理由要求本站停止使用有关图片，其中包括被本站编辑（比如加注说明）过的图片， 联系方式见本站首页。 ","date":"2021-11-01","objectID":"/about/:3:0","tags":null,"title":"关于","uri":"/about/"},{"categories":["Docker"],"content":"kubernetes deploy","date":"2018-06-07","objectID":"/k8s-deploy/","tags":["docker","kubernetes"],"title":"K8S-Deploy","uri":"/k8s-deploy/"},{"categories":["Docker"],"content":"部署 Kubernetes 阿里云有提供一套可用的 k8s，如果自己部署的话就不需要再依赖于阿里云相关文档中所要求的环境。 ","date":"2018-06-07","objectID":"/k8s-deploy/:0:0","tags":["docker","kubernetes"],"title":"K8S-Deploy","uri":"/k8s-deploy/"},{"categories":["Docker"],"content":"准备工作 运行 deb/rpm 兼容操作系统的一台或多台机器，例如 Ubuntu 或 CentOS 每台机器 2GB 或更多内存 master 上的 CPU 要求 2 核或以上 集群中所有机器（公用或专用网络都可以）的网络都是可连通的 ","date":"2018-06-07","objectID":"/k8s-deploy/:1:0","tags":["docker","kubernetes"],"title":"K8S-Deploy","uri":"/k8s-deploy/"},{"categories":["Docker"],"content":"安装 kubeadm ","date":"2018-06-07","objectID":"/k8s-deploy/:2:0","tags":["docker","kubernetes"],"title":"K8S-Deploy","uri":"/k8s-deploy/"},{"categories":["Docker"],"content":"准备工作 操作系统为 Ubuntu 16.04+ 禁用 Swap。为了让 kubelet 正常工作你必须禁用 swap。 安装 Docker 在你的每一台机器上安装 Docker。建议使用的版本号为 17.03。而 1.11， 1.12 和 1.13 是可以正常使用的。17.06+ 可以用，但是 Kubernetes 团队还没有测试和验证。 如果你已经安装了要求的 Docker 版本，你可以进入下一部分了。如果没有，请用下面的命令安装 Docker。 apt-get update apt-get install -y docker.io 或者安装 Docker CE 17.03 apt-get update apt-get install -y apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add - add-apt-repository \"deb https://download.docker.com/linux/$(. /etc/os-release; echo \"$ID\") $(lsb_release -cs) stable\" apt-get update \u0026\u0026 apt-get install -y docker-ce=$(apt-cache madison docker-ce | grep 17.03 | head -1 | awk '{print $3}') 这里是 Docker 官方的安装指南 ","date":"2018-06-07","objectID":"/k8s-deploy/:2:1","tags":["docker","kubernetes"],"title":"K8S-Deploy","uri":"/k8s-deploy/"},{"categories":["Docker"],"content":"安装 kubeadm, kubectl, kubelet 版本号：1.10.3-00 kubeadm: 引导启动 k8s 集群的命令工具。 kubelet: 在群集中的所有计算机上运行的组件, 并用来执行如启动 pods 和 containers 等操作。 kubectl: 用于操作运行中的集群的命令行工具。 sudo apt-get update \u0026\u0026 sudo apt-get install -y apt-transport-https curl -s http://packages.faasx.com/google/apt/doc/apt-key.gpg | sudo apt-key add - sudo cat «EOF \u003e/etc/apt/sources.list.d/kubernetes.list deb http://mirrors.ustc.edu.cn/kubernetes/apt/ kubernetes-xenial main EOF sudo apt-get update sudo apt-get install -y kubelet kubeadm kubectl apt-key 官方地址为：https://packages.cloud.google.com/apt/doc/apt-key.gpg。 apt安装包地址使用了中科大的镜像，官方地址为：http://apt.kubernetes.io/。 从该链接 https://raw.githubusercontent.com/EagleChen/kubernetes_init/master/kube_apt_key.gpg 下载 kube_apt_key.gpg 到当前工作目录下，并按如下指令添加 $ cat kube_apt_key.gpg | sudo apt-key add - 显示 OK 即表示成功 ","date":"2018-06-07","objectID":"/k8s-deploy/:2:2","tags":["docker","kubernetes"],"title":"K8S-Deploy","uri":"/k8s-deploy/"},{"categories":["Docker"],"content":"下载 k8s 镜像 docker pull anjia0532/kube-proxy-amd64:v1.10.3 \\ \u0026\u0026 docker pull anjia0532/kube-controller-manager-amd64:v1.10.3 \\ \u0026\u0026 docker pull anjia0532/kube-scheduler-amd64:v1.10.3 \\ \u0026\u0026 docker pull anjia0532/kube-apiserver-amd64:v1.10.3 \\ \u0026\u0026 docker pull anjia0532/k8s-dns-dnsmasq-nanny-amd64:1.14.8 \\ \u0026\u0026 docker pull anjia0532/k8s-dns-sidecar-amd64:1.14.8 \\ \u0026\u0026 docker pull anjia0532/k8s-dns-kube-dns-amd64:1.14.8 \\ \u0026\u0026 docker pull anjia0532/pause-amd64:3.1 \\ \u0026\u0026 docker pull quay.io/coreos/flannel:v0.10.0-amd64 ","date":"2018-06-07","objectID":"/k8s-deploy/:2:3","tags":["docker","kubernetes"],"title":"K8S-Deploy","uri":"/k8s-deploy/"},{"categories":["Docker"],"content":"修改 image tag docker tag anjia0532/kube-proxy-amd64:v1.10.3 k8s.gcr.io/kube-proxy-amd64:v1.10.3 \\ \u0026\u0026 docker tag anjia0532/kube-controller-manager-amd64:v1.10.3 k8s.gcr.io/kube-controller-manager-amd64:v1.10.3 \\ \u0026\u0026 docker tag anjia0532/kube-scheduler-amd64:v1.10.3 k8s.gcr.io/kube-scheduler-amd64:v1.10.3 \\ \u0026\u0026 docker tag anjia0532/kube-apiserver-amd64:v1.10.3 k8s.gcr.io/kube-apiserver-amd64:v1.10.3 \\ \u0026\u0026 docker tag anjia0532/k8s-dns-dnsmasq-nanny-amd64:1.14.8 k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.14.8 \\ \u0026\u0026 docker tag anjia0532/k8s-dns-sidecar-amd64:1.14.8 k8s.gcr.io/k8s-dns-sidecar-amd64:1.14.8 \\ \u0026\u0026 docker tag anjia0532/k8s-dns-kube-dns-amd64:1.14.8 k8s.gcr.io/k8s-dns-kube-dns-amd64:1.14.8 \\ \u0026\u0026 docker tag anjia0532/pause-amd64:3.1 k8s.gcr.io/pause-amd64:3.1 需要下载 crictl USER 与 IP 修改为自己的 $ wget https://github.com/kubernetes-incubator/cri-tools/releases/download/v1.0.0-beta.1/crictl-v1.0.0-beta.1-linux-amd64.tar.gz $ tar xvf crictl-v1.0.0-beta.1-linux-amd64.tar.gz $ sudo chown root:root crictl $ sudo cp crictl /usr/bin $ scp crictl USER@IP:/home/USER $ sudo chown root:root crictl $ sudo mv crictl /usr/bin/ 上面的步骤需要在所有机器上安装 ","date":"2018-06-07","objectID":"/k8s-deploy/:2:4","tags":["docker","kubernetes"],"title":"K8S-Deploy","uri":"/k8s-deploy/"},{"categories":["Docker"],"content":"初始化 master 节点 $ sudo kubeadm init --apiserver-advertise-address=10.66.180.159 --pod-network-cidr=10.244.0.0/16 --feature-gates=CoreDNS=true --kubernetes-version=v1.10.3 输出 [init] Using Kubernetes version: v1.10.3 [init] Using Authorization modes: [Node RBAC] [preflight] Running pre-flight checks. [WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 18.03.1-ce. Max validated version: 17.03 [preflight] Starting the kubelet service [certificates] Generated ca certificate and key. [certificates] Generated apiserver certificate and key. [certificates] apiserver serving cert is signed for DNS names [org2 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.66.180.159] [certificates] Generated apiserver-kubelet-client certificate and key. [certificates] Generated etcd/ca certificate and key. [certificates] Generated etcd/server certificate and key. [certificates] etcd/server serving cert is signed for DNS names [localhost] and IPs [127.0.0.1] [certificates] Generated etcd/peer certificate and key. [certificates] etcd/peer serving cert is signed for DNS names [org2] and IPs [10.66.180.159] [certificates] Generated etcd/healthcheck-client certificate and key. [certificates] Generated apiserver-etcd-client certificate and key. [certificates] Generated sa key and public key. [certificates] Generated front-proxy-ca certificate and key. [certificates] Generated front-proxy-client certificate and key. [certificates] Valid certificates and keys now exist in \"/etc/kubernetes/pki\" [kubeconfig] Wrote KubeConfig file to disk: \"/etc/kubernetes/admin.conf\" [kubeconfig] Wrote KubeConfig file to disk: \"/etc/kubernetes/kubelet.conf\" [kubeconfig] Wrote KubeConfig file to disk: \"/etc/kubernetes/controller-manager.conf\" [kubeconfig] Wrote KubeConfig file to disk: \"/etc/kubernetes/scheduler.conf\" [controlplane] Wrote Static Pod manifest for component kube-apiserver to \"/etc/kubernetes/manifests/kube-apiserver.yaml\" [controlplane] Wrote Static Pod manifest for component kube-controller-manager to \"/etc/kubernetes/manifests/kube-controller-manager.yaml\" [controlplane] Wrote Static Pod manifest for component kube-scheduler to \"/etc/kubernetes/manifests/kube-scheduler.yaml\" [etcd] Wrote Static Pod manifest for a local etcd instance to \"/etc/kubernetes/manifests/etcd.yaml\" [init] Waiting for the kubelet to boot up the control plane as Static Pods from directory \"/etc/kubernetes/manifests\". [init] This might take a minute or longer if the control plane images have to be pulled. [apiclient] All control plane components are healthy after 20.001731 seconds [uploadconfig] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace [markmaster] Will mark node org2 as master by adding a label and a taint [markmaster] Master org2 tainted and labelled with key/value: node-role.kubernetes.io/master=\"\" [bootstraptoken] Using token: yof8me.re7zttbijtwmdavm [bootstraptoken] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstraptoken] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstraptoken] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstraptoken] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes master has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts","date":"2018-06-07","objectID":"/k8s-deploy/:2:5","tags":["docker","kubernetes"],"title":"K8S-Deploy","uri":"/k8s-deploy/"},{"categories":["Docker"],"content":"加入集群 token 需要换成自己初始化时生成的。 kubeadm join 10.66.180.159:6443 --token yof8me.re7zttbijtwmdavm --discovery-token-ca-cert-hash sha256:507756057bf6982624fa07bbbbdab0855d555c809ec185aac10de95a00c77e2b --ignore-preflight-errors=cri ","date":"2018-06-07","objectID":"/k8s-deploy/:2:6","tags":["docker","kubernetes"],"title":"K8S-Deploy","uri":"/k8s-deploy/"},{"categories":["Docker"],"content":"常用命令 kubeadm 常用命令 kubeadm init kubeadm join kubeadm upgrade kubeadm config kubeadm reset kubeadm token kubeadm version kubeadm alpha kubectl 常用命令 kubectl get node --show-labels kubectl get nodes ","date":"2018-06-07","objectID":"/k8s-deploy/:2:7","tags":["docker","kubernetes"],"title":"K8S-Deploy","uri":"/k8s-deploy/"},{"categories":["Docker"],"content":"参考文档 Google Container Registry(gcr.io) 中国可用镜像(长期维护) 使用 kubeadm 搭建 Kubernetes(1.10.2) 集群（国内环境） ubuntu下使用 kubeadm 安装部署 kubernetes v1.10 使用 kubeadm 创建集群–官方文档 kubeadm 设置工具参考指南 ","date":"2018-06-07","objectID":"/k8s-deploy/:2:8","tags":["docker","kubernetes"],"title":"K8S-Deploy","uri":"/k8s-deploy/"},{"categories":["区块链"],"content":"ipfs readme","date":"2018-05-21","objectID":"/ipfs-readme/","tags":["blc","IPFS"],"title":"IPFS README","uri":"/ipfs-readme/"},{"categories":["区块链"],"content":"IPFS README 简介 从 gitbook 上发现了这本书的英文版，所以想把它翻遍成中文版，如果你有兴趣，可以一起:), 目前仅做学习交流用。只有晚上有时间更新。 这份简介包括一系列说明 IPFS，Merkle Trees 和 分布式网络的教程，它主要通过 gitbook 来编辑和完善，所以大家可以用多种格式来阅读。 当完成时，这份简介将完全替换这个 https://ipfs.io/docs/examples/ 这本书的 github 英文版仓库是: [ https://github.com/flyingzumwalt/decentralized-web-primer 获得帮助 在学习该教程的过程中，如果你有任何的问题随时都可以在 the IPFS 论坛 或 访问 chat.freenode.net 进入ipfs频道进行咨询。在上面我们有一个庞大、活跃的群体都在此寻求帮助或发表见解。 教程 这个入门教程包含以下内容： 下载和安装 IPFS IPFS 中的文件 在线 – 加入分布式网页 (Web) 与经典 (HTTP) 网页 (Web) 的联系 无数种访问和分发 IPFS 内容的方式 Merkle Trees 和 IPFS DAG IPFS 上的动态内容 有关教程的完整内容，请查看目录 概念 加密哈希和内容可寻址性 经过身份验证的图形（Graphs） 将文件转换成树 将任意数据转换成树 在 DHT 上发布 哈希 从 P2P 网络获取数据 不可变性：『改变』作为树的补充 CRDTs 发布订阅 认证流（带有发布订阅） 格式 每个教程都是一组课程，都使用受 Railsbridge Curriculum 启发的格式。每节课都声明一组目标，或者 learning objectives，然后列出步骤或活动，最后提供一个解释，回顾你已经完成的任务，并将这些活动与课程的既定目标相联系。每个课程的格式如下所示： 贡献者的注意事项 有关学习目标（本书中称为目标）的简要说明，请阅读UC Denver的 Assessment \u0026 Instructional Alignment Tutorial。尽量让你的学习目标 具体，可观察和可衡量，并听取他们的建议，使用 分类工作表 中的动词列表来帮助你为课程学习目标选择可观察的行为。 用一个命令构建本书的 HTML，PDF，epub 和 mobi 版本，运行./build-book.sh 贡献者 这个入门教程是由 @flyingzumwalt 创建的 这些教程的内容最初是从 ipfs 网站 和 ipfs 示例 的 git 存储库中的文档中提取的。 包括贡献那些原始文档的人 @whyrusleeping @jbenet @lgierth @lynnandtonic @wraithgar @adambrault @donothesitate @djdv 加上一个长长的贡献者库的名单 ","date":"2018-05-21","objectID":"/ipfs-readme/:0:0","tags":["blc","IPFS"],"title":"IPFS README","uri":"/ipfs-readme/"},{"categories":["区块链"],"content":"IPFS Summary Summary ","date":"2018-05-21","objectID":"/ipfs-summary/:0:0","tags":["blc","IPFS"],"title":"IPFS Summary","uri":"/ipfs-summary/"},{"categories":["区块链"],"content":"Introduction Introduction ","date":"2018-05-21","objectID":"/ipfs-summary/:1:0","tags":["blc","IPFS"],"title":"IPFS Summary","uri":"/ipfs-summary/"},{"categories":["区块链"],"content":"第 1 章：安装和初始化 IPFS 简介 下载和安装 IPFS 初始化你的 IPFS 仓库 ","date":"2018-05-21","objectID":"/ipfs-summary/:2:0","tags":["blc","IPFS"],"title":"IPFS Summary","uri":"/ipfs-summary/"},{"categories":["区块链"],"content":"第 2 章: IPFS 中的文件 简介 上传文件到 IPFS 并检索它 打包有关内容的文件名与目录信息 Pinning – 告诉 IPFS 保留文件 ","date":"2018-05-21","objectID":"/ipfs-summary/:3:0","tags":["blc","IPFS"],"title":"IPFS Summary","uri":"/ipfs-summary/"},{"categories":["区块链"],"content":"第 3 章：网络在线 – 加入分布式 Web 简介 在 IPFS 网络上发布您的节点 在网络上寻找 Peers 从一个 Peer(节点) 中检索内容 ","date":"2018-05-21","objectID":"/ipfs-summary/:4:0","tags":["blc","IPFS"],"title":"IPFS Summary","uri":"/ipfs-summary/"},{"categories":["区块链"],"content":"第 4 章：与经典（HTTP）网络交互 简介 使用 HTTP 浏览器从本地 IPFS 网关检索文件 通过公共的 ipfs.io 网关获取文件内容 通过任意 IPFS 网关访问 IPFS 的内容 TODO 将 DNS 映射到 IPNS TODO 在 IPFS 上的流媒体视频 ","date":"2018-05-21","objectID":"/ipfs-summary/:5:0","tags":["blc","IPFS"],"title":"IPFS Summary","uri":"/ipfs-summary/"},{"categories":["区块链"],"content":"第 5 章：访问和分发 IPFS 的多种方式 简介 内容寻址的能力 从一个 Peer(节点) 中检索内容 阅读关于与经典(HTTP) 网络交互的教程 使用 HTTP 浏览器从本地 IPFS 网关检索文件 在 ipfs.io 上使用公共 IPFS 网关 通过任意 IPFS 网关访问 IPFS 的内容 通过 Tor 网关访问 IPFS 内容（实验性） 通过 Tor transport 运行 IPFS 通过浏览器插件访问 IPFS 内容 Sneakernets – 移动 USB 驱动器和其它硬件上的数据 ","date":"2018-05-21","objectID":"/ipfs-summary/:6:0","tags":["blc","IPFS"],"title":"IPFS Summary","uri":"/ipfs-summary/"},{"categories":["区块链"],"content":"第 6 章：在 Permanent Web 上发布更改 简介 在 IPFS节点上设置 IPNS 创建一个指向你的文件的 IPNS 条目 修改你的文件并将修改后的版本添加到 IPFS 更新 IPNS 条目以指向新和版本 ","date":"2018-05-21","objectID":"/ipfs-summary/:7:0","tags":["blc","IPFS"],"title":"IPFS Summary","uri":"/ipfs-summary/"},{"categories":["区块链"],"content":"第 7 章：分布式 Web 上的隐私和访问权限控制 简介 读者隐私和写作者的隐私 专用(private)网络 加密内容 更多的动态加密：基于能力的加密 与经典 HTTP 网站相比（封建(feudal)安全等） ","date":"2018-05-21","objectID":"/ipfs-summary/:8:0","tags":["blc","IPFS"],"title":"IPFS Summary","uri":"/ipfs-summary/"},{"categories":["区块链"],"content":"第 8 章：保持数据活跃：常驻(permanent) Web 上的可持续数据 简介 IPFS 集群 Filecoin ","date":"2018-05-21","objectID":"/ipfs-summary/:9:0","tags":["blc","IPFS"],"title":"IPFS Summary","uri":"/ipfs-summary/"},{"categories":["区块链"],"content":"第 9 章：Merkle Trees 和 IPFS DAG 简介 将文件转换成哈希树 创建一个加密哈希 在 IPFS 中使用加密哈希来链接这些碎片（Merkle DAG） 探索使用哈希树来跟踪数据的软件类型 ","date":"2018-05-21","objectID":"/ipfs-summary/:10:0","tags":["blc","IPFS"],"title":"IPFS Summary","uri":"/ipfs-summary/"},{"categories":["区块链"],"content":"第 10 章：在 IPFS 上的动态内容 简介 免责声明：IPFS 上的动态内容是一项正在进行的工作 将数据添加到 DAG（本地） 将你的更改告诉 Peers 使用哈希来从 IPFS 上获取他人的修改 使用发布订阅策略来传递有关修改的消息 ","date":"2018-05-21","objectID":"/ipfs-summary/:11:0","tags":["blc","IPFS"],"title":"IPFS Summary","uri":"/ipfs-summary/"},{"categories":["区块链"],"content":"第 11 章：分布式计算 简介 ","date":"2018-05-21","objectID":"/ipfs-summary/:12:0","tags":["blc","IPFS"],"title":"IPFS Summary","uri":"/ipfs-summary/"},{"categories":["读书笔记"],"content":"99 个史上更全面的时间管理技巧","date":"2018-04-05","objectID":"/the-little-book-of-productivity/","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"超效率手册 这本书的作者是加拿大人 斯科特·扬（Scott Young）, 他有自己的学习类博客和网站。这本书中提出了 99 个方法能帮你在更短的时间内做更多的事情。 第一章 克服拖延症 作者在这一章里提到了 14 种方法， 周/日目标 限定时间 分解任务 短跑理论 日程校对 加强自律 使用咒语 根除潜在的绊脚石 动力催化剂 搅拌 营造一个不会分心的工作场所 拒绝『应该』 预备、射击、瞄准 摒弃拖延恶习 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:0:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"周/日目标 主要讲解的是通过对任务的分解，明确目标。 在每周的最后一天列出你下一周想要完成的工作。 在每天结束时，把明天要完成的目标准备好。 一旦完成了一天的目标，就停止一天的工作。 我想第三条对大多数人都很难做到吧。当我们提前完成了一天的任务时，我们可能更多的会想继续做之后的事，而不是就这么结束。 当然作者只是说停止工作，其实你就有时间可以做其他的事情了。这样其实对大脑的放松有一定的好处，让我们的存储脑可以开始整理和关联的工作。因为在《慢思考》中提到，我们的大脑主要分为有三个大的区域：反射脑、思考脑、存储脑。当你在工作时，大脑中的思考脑占用大部分的资源，当你在休息时，你的存储脑就抓紧时间来占用来用的所有资源来处理你在工作中的内容。 每周的工作任务列出来会让你专注于大的规划，而每天的工作任务则会让你远离压力，更轻松的面对。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:1:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"限定时间 限定时间是指在工作完成之前或在时间用完之前不可以停下来。目的是为了提高效率，刚开始可能会比较『残酷』。但是会有收获。它可以击退你心中的拖延恶魔，哈哈。表现在两个方面： 时间短（30 ~ 90 分钟）：这个其实也可以考虑一下『蕃茄工作法』，主要目的是为了让人更容易接受，更合理的利用大脑来工作。 紧追感：限定时间会刺激你加快速度 限定时间会让你更集中注意力，在这个过程中你会超过设定的时间，你会更容易持续工作。 限定时间是你开始工作的第一的推动力。 所以当你不想工作时，你就可以设定一个 90 分钟的『时间盒子』，清理你的桌子，关掉收件箱，专心工作 90 分钟。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:2:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"分解任务 工作或学习中，我们应该都知道，相比于简单电明了的事，越是不明确的大型任务，我们越不知道应该如何下手，所以我们要学会分解任务。 你的任务必须将接下来 60 秒该做什么都写得清清楚楚。刚开始做这件事是有一定难度的，可这正是你学习分析问题，分解任务的好时机呀。 分解你不喜欢的任务。 分解那些没有明确截止时间的任务。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:3:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"短跑理论 掌握短跑理论是进行自律的关键 短跑理论适用于一些纪律性很强的任务。 举几个例子： 起床：闹钟响后，强迫自己清醒并保持 10 分钟。 习惯：坚持一个习惯 30 天 创作阻碍：再坚持创作 20 分钟。然后休息。 这里讲的主要意思就是 做事要有自律性，要坚持，保持规律。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:4:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"日程校对 我小的时候都听过那个从梯子上跳下来他爸说会接住他，但是他爸并没有去接住他，他直接摔在了地上的故事。我们可以理解缺少信任会破坏一段关系，但我们很难明白缺乏信任是如何让人产生拖延习惯的。 如果你不相信自己要办的事情就会拖延。以完成列表上的任务为标准，完成后不要再去加一些，因为那样做就是在破坏信任。因此，你很难再次激励自己。 日程校对是当你对你的待办事项有充分信任的时候所做的事。做完就停下不要再去添加任务了。这样就会避免过度工作，也不会养成懒惰的习惯。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:5:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"加强自律 文中说练习自律就像举重。是的人本身就是懒惰的。在《少有人走的路》那本书中说人的原罪是懒惰。如果你是一个懒惰的人那那你的身材很可能会走样。作者说 懒惰并不存在于你的血夜里，而存在于你的肌肉里。我觉得这个说法挺有意思的，他在告诉你这其实是一种习惯，它是可以被改变的。作者提出的几个方法： 下一次你想停下来工作的时候，再坚持 10 分钟。过了放弃的门槛，就锻炼了肌肉。 在思想不集中之前，搞清楚你能持续工作的时间，下一次工作的时候，坚持多做 10% ~ 20%。 你的心思会在不同项目之间跳来跳去吗？给下个月设定一个目标，专注于一件事情。 作者说，通过阻力训练，意志力同样可以帮你到这个程度。 我想在这个过程中你做到了就会给自己一个（短暂的）休息时间和奖励。因为意志力本身就是一种消耗品。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:6:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"使用咒语 咒语是你经常重复对自己说的话。这个事情我是有体会的，特别是在爬山的时候，当身体累的时候，我会跟自己说『你可以的，U can do it!』这样的话，可以给人的感觉像个神经病，不过它会让你的精神状态好很多。 我的桌面有一句话，这句话是我在看『知乎』 的一篇文章时看到的，原话是：when you get the feeling that your work is ok,you have got killed another you who can make it much better. ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:7:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"根除潜在的绊脚石 在这一段里我认为作者说了最重要的部分，就是要分析你产生拖延症的真正原因。如果你做了前面说的很多事情，并没有什么改变，没法调动起自己的积极性，那问题就可能出在『土壤』里，你要找到最根本性的原因，要不然你所做的所有事都是徒劳无效的，并且这会让你更糟糕。作者也说了几种方法来分析： 我专注实现的目标还能激励我吗？ 我想要生产效率高的原因对我还有意义吗？ 我是不是把『生产效率』当作借口来回避真正的恐惧和梦想？ 这件事情需要在你开始提升生产效率技能，增加工业肥料之前进行。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:8:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"动力催化剂 这个可以理解为给自己提高实现目标的动力。作者举了几个例子： 把你的目标列成一个表。放在一个你经常能够看到的地方 做出公开承诺。产生的压力会让你保持动力 便利贴。同样是提醒的作用 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:9:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"搅拌 搅拌是生产垃圾的艺术。我感觉这个『搅拌』是不是翻译的问题 这一段要表达的意思就是一件事情你刚开始可能会做的不好，但是你要坚持去不断的去做。刚开始可以选择降低自己的标准，这样可以让你开始做事，远离创作的阻碍。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:10:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"营造一个不会分心的工作场所 拖延者喜欢分心。但是避免拖延的关键就是不分心。下面是一些初级方法： 电脑上。关掉不用的东西，断网等手段，这些我想你应该都听过 书桌上。清理干净 屏蔽『噪声』。在门上帖一个『禁止打扰』的标签 让人们知道你的『专注』时间 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:11:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"拒绝『应该』 『应该』不是会激励你的，它只会在你不工作的时候让你感到内疚。 这一点其实是可以学习的，因为它在你『想要做』 和 『不去做』的事。划出了一条界线。并且没有『应该做』这样的事 怎么解决『应该做』的问题呢？ 如果能够找到具体的任务与目标之间的强关联（哪怕是间接的），那就是想要做的。 如果跟你的主要目标没有什么联系，那你就直接把它归入『不去做』的行列吧 这一条主要告诉我的是：根据主要目标来做判断 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:12:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"预备、射击、瞄准 这一条讲的是说，我们在做事情时有时候更倾向于 预备–\u003e瞄准–\u003e射击 这样的环节。而我们在瞄准阶段会遇到困难。所以我们可以使用 预备、射击、瞄准 这样的流程。 如果能收到反馈，就会瞄得更准。 极限编程就使用这样的方法来有效地设计程序，这样就会避免设计一些笨重、庞大的程序出来 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:13:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"摒弃拖延恶习 每个人都有拖延的恶习。可能是 看电视，玩电子游戏或者漫无目的地上网。摒弃掉这些习惯就能把节省的时间重新投入到真正感兴趣的事情上面。 戒掉这些习惯并不是切掉你生活乐趣的来源。因为大多数人看电视老师因为舒适、不费劲，并不是因为电视能给他们的生活带来什么。网络也是一样的。把占据你很多时间但没有什么价值的事情列一个表。然后尽力做到下面两点之一。 彻底根除这个习惯 压缩这个习惯，谨慎行事。如果你真的很喜欢一档电视节目，可以考虑把它录下来，否则，直接关掉电视。 我现在也有自己喜欢的节目，我会选择从网上看回播。 在第一章里内容可以概括为制定在规定时间可以完成的任务，然后做任务拆分，之后就到了执行层面了，通过日程校对等方法来保证任务会被正常推进，同时讲到了激励自己坚持做下来的一些方法。整体读下来我认为我缺少的是执行力和 拒绝『应该』 做事更有条理 第二章主要包括下面的内容 条理性是一种技能 少点儿混乱，少点儿压力 捕捉装置 给所有东西规定放置的地方 简单的组织系统 简单的组织系统：项目 简单的组织系统：任务 简单的组织系统：活动 写出你的目标 分支法 通信记录 做你承诺过的事 整齐 VS 有条理 阅读笔记 数字条理性 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:14:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"条理性是一种技能 条理性是一种可以学习的技能。不是天生的！ 条理性要靠专门的设计和保持。定期维护是必须的。 这里讲的主要意思就是做事要有条理，如果你现在没有条理，是可以通过练习来学习的。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:15:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"少点儿混乱，少点儿压力 条理性与生产效率的关系极其微弱。条理性的真正目的在于减少记住所有事情所需要的脑力。毕竟你的头脑并非那么可靠 你的物理环境 你的任务和工作 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:16:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"捕捉装置 这里讲的主要意思就是我们无论在什么时候都会有灵感或一些有趣的想法，那我们手头最好是有一个可以记录下来的卡片和一支笔。 因为捕捉装置是解除记忆压力的首要方法 拥有一个捕捉装置也是尊重他人的体现。 现在像人们可能都会用手机来做记录。 这条建议出自热衷条理性的人们奉为圣经的《搞定》（Get things done, GTD）。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:17:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"给所有东西规定放置的地方 这一条主要告诉我的是：每个东西规定一个放置的地方。家里的每一个物品都应该放在该放的地方。 这一点我做到了。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:18:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"简单的组织系统 作者没有直接用 GTD，因为 GTD 中有很多分类，但很多是大部分人不需要的。 我的三大类是项目、任务和活动，当然那 1% 无法归入的特殊情况，专门有一个杂项的表来收集这些随机的想法。 维护三大类相对容易，因为太多的大类，我们并不会定期检查任何一类。而三大类可以方便查找，不会废弃不用。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:19:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"简单的组织系统：项目 一个项目是有共同目标的许多个任务的集合。 完成项目而非任务是十分重要的，所以我更加注重灵活性。一个任务的牺牲可以的来整个项目的完成，那就可以先不写 项目相对稳定，不会因为新的信息而被快速更新。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:20:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"简单的组织系统：任务 任务就是具体要去做的事。任务是一些需要完成的比较小的、独立的行动。任务有三个部分： 总体待办事项：包含那些既不属于项目也不属于活动 周目标 日目标 如果有新加进来的任务，那可以直接添加到周目标或日目标里面 作者使用的是 Tadalist （一个列表工具）做这三个待办事情列表。链接点我 上获取一个免费的 Tadalist 账号。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:21:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"简单的组织系统：活动 通过 谷歌日历 来记录活动 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:22:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"写出你的目标 将目标写下来有几个好处： 让目标不被遗忘 给你动力去完成目标 可以让你有一些模糊的想法，并把它们变成具体的目标 作者说他更喜欢用纸来写下目标是因为这样更具体，更加切实可行。我也喜欢用纸写，包括一些笔记然后再整理到我的印象笔记里 已经完成的目标会带给你巨大的动力。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:23:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"分支法 我的组织哲学是分支法。我相信人无法提前设计一个完美的组织系统。不如建立下一步工作能随时适应新变化的系统 分支法就是这样一个系统。你要定期检查你的组织系统。检查的时候注意这几件事情： 有没有哪些类别包含了太多的东西？如果有，把它分成小的类别 有没有哪些类别没有用过？把它归入一个相关的类。 有没有可以建立的新类别？如果你有新的工作，可以选择建立一些以前没有的类别单独分开它们，避免跟已有的系统混在一起 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:24:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"通信记录 通信记录这个像电话销售和售后服务员会需要用到 通话记录有用，是因为： 看你的承诺是否实现。 查看联系的时间 把通信记录归入你的组织系统 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:25:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"做你承诺过的事 作者认为 60% 保证做却没有做到的事情老师因为忘记了，而不是因为做不到 记录下你做过的承诺，然后整理到你的目标中。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:26:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"整齐 VS 有条理 整齐是表面的干净整洁。 有条理：是一个让你找到东西和储存东西都变得容易的系统 你要做到： 把新的东西准备在该放的地方 找到你需要的东西不能花费太长时间 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:27:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"阅读笔记 整理笔记其实是有用的： 它帮助你抓住一本书的想要表达的内容。 它比书页折角和画下划线快。在书上做笔记是很快的，但事后你想查看起来就慢多了。在笔记本上记录可以让你更快地回忆书上内容。 你的记忆悄是完美的。 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:28:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["读书笔记"],"content":"数字条理性 原则：给每个东西一个放置的地方，定期维护，并寻找变化。 数字存储几乎是无限的。定期清理 分支非常容易。清除不用的文件 这个应该是翻译的问题，读起来感觉不是很理解 ","date":"2018-04-05","objectID":"/the-little-book-of-productivity/:29:0","tags":["books","productivity"],"title":"超效率手册","uri":"/the-little-book-of-productivity/"},{"categories":["区块链"],"content":"IPFS 的简单了解","date":"2018-04-04","objectID":"/ipfs/","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"IPFS 这篇文章的原文是在 Gavin的博客 读下来后不是很懂。感觉中文的有些生硬和不好理解的地方，记录一下，继续研究。 摘要 星际文件系统是一种点对点的分布式文件系统, 旨在连接所有有相同的文件系统的计算机设备而IPFS是一个单一的Bittorrent 群集， 用git 仓库分布式存储 IPFS 提供了高吞吐量的内容寻址块存储模型， 具有内容寻址的超链接 IPFS 结合了分布式哈希表,带有激励机制的块交换和自我认证命名空间 IPFS 没有单故障点， 节点不需要相互信任 介绍 在学术尝试中 AFS【6】 AFS【7】 Napster, KaZaA 和BitTorrent[2]部署的文件分发系统支持1亿用户的同时在线 我们正在进入数据分发的新纪元 （a）托管和分发 PB 级数据集 （b）跨组织的大数据计算 （c）大批量的高清晰度按需或实时媒体流 （d）大规模数据集的版本化和链接 （e）防止意外丢失重要文件等。其中许多可以归结为“大量数据，无处不在”。由于关键功能和带宽问题，我们已经为不同的数据放弃了HTTP 分销协议。下一步是使它们成为web自己的一部分。 有效的数据分发， 版本控制系统: Git是分布式源代码版本控制系统 已经设法开发重要的数据协作工作流程 Git 启发的新解决方案正在出现 - Camlistore： 个人文件存储系统 - Dat： 数据协作工具链和数据集包管理器 IPFS 是一种新颖的对等版本控制的文件系统，旨在调和这些问题 ","date":"2018-04-04","objectID":"/ipfs/:0:0","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"背景 ","date":"2018-04-04","objectID":"/ipfs/:1:0","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"分布式哈希表（DHT） 分布式散列表（DHT）被广泛用于协调和维护关于对等系统的元数据 KADEMLIA DHT Kademlia[10] 是受欢迎的DHT, 它提供 - 1.通过大量网络进行高效查询 - 2.低协调开销：优化数量的控制消息发送到其他节点 - 3.抵抗各种攻击，喜欢长寿节点 - 4.在对等应用中广泛使用，包括 Gnutella 和 BitTorrent, 形成了超过 2000 万个节点的网络 CORAL DSHT 我的理解：防止浪费存储和带宽的 虽然一些对等文件系统直接在 DHT 中存储数据块，这种“数据存储在不需要的节点会浪费存储和带宽”[5]。Coral DSHT 扩展了 Kademlia 三个特别重要的方式 1.Kademlia 在 ids 为“最近”（使用 XOR-distance）的关键节点中存储值。这不考 虑应用程序数据的局部性，忽略“远”可能已经拥有数据的节点，并强制“最近”节点存储它，无论它们是否需要。这浪费了大量的存储和带宽。相反，Coral 存储了地址，该地址的对等节点可以提供相应的数据块。 2.Coral 将 DHT API 从 get_value(key)换成了 get_any_values(key)（DSHT 中的 “sloppy”）中。这仍然是因为 Coral 用户只需要一个（工作）的对等体，而不是完整的列表。作为回报，Coral 可以仅将子集分配到“最近”的节点，避免热点（当密钥变得流行时，重载所有最近的节点）。 3.另外，Coral 根据区域和大小组织了一个称为群集的独立 DSHT 层次结构。这使得节点首先查询其区域中的对等体，“查找附近的数据而不查询远程节点”[5]并大大减少查找的延迟。 S/KADEMLIA DHT 我的理解：防止恶意的攻击 S/Kademlia[1] 扩展了Kademlia, 用于防止恶意的攻击。有如下两方面的方法： 1.S/Kad 提供了方案来保证 NodeId 的生成已经防止 Sybill 攻击。它需要节点产生 PKI 公私钥对。从中导出他们的身份，并彼此间签名。一个方案使用 POW 工作量证明，使得生成 Sybills 成本高昂。 2.S/Kad 节点在不相交的路径上查找直，即使网络中存在大量的不诚实节点，也能确保诚实节点可以互相链接。即使网络中存在一半的不诚实节点，S/Kad 也能达到 85% 的成功率。 ","date":"2018-04-04","objectID":"/ipfs/:1:1","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"块交换 - BitTorrent BitTorrent[3] 是一个广泛成功应用的点对点共享文件系统，它可以在存在不信任的对等节点（群集）的协作网络中分发各自的文件数据片。从BitTorrent和它的生态系统的关键特征， IPFS得到启示如下： 1.BitTorrent的数据交换协议使用了一种bit-for-tat的激励策略， 可以奖励对其他方面做贡献的节点，惩罚只榨取对方资源的节点 2.BitTorrent对等体跟踪文件的可用性，优先发送稀有片段。这减轻了seeds节点的负担， 让non-seeds节点有能力互相交易 3.对于一些剥削带宽共享策略， BitTorrent的标准tit-for-tat策略是非常脆弱的。 然而，PropShare[8]是一种不同的对等带宽分配策略， 可以更好的抵制剥削战略， 提高群集的表现。 ","date":"2018-04-04","objectID":"/ipfs/:1:2","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"版本控制系统 - Git 版本控制系统提供了对随时间变化的文件进行建模的设施，并有效地分发不同的版本。流行版本控制系统 Git 提供了强大的 Merkle DAG 对象模型，以分布式友好的方式捕获对文件系统树的更改。 1.不可更改的对象表示文件（blob），目录（树）和更改（提交） 2.通过加密hash对象的内容，让对象可寻址 3.链接到其他对象是嵌入的，形成一个Merkle DAG。这提供了很多有用的完整和work-flow属性 4.很多版本元数据（分支，标示等等）都只是指针引用，因此创建和更新的代价都小 5.版本改变只是更新引用或者添加对象 6.分布式版本改变对其他用户而言只是转移对象和更新远程引用 ","date":"2018-04-04","objectID":"/ipfs/:1:3","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"自我认证的文件系统 - SFS SFS [ 12，11 ]提出了两个引人注目的实现（a）分布式信任链，和（b）平等共享的全局命名空间。SFS 引入了一种自我建构技术—注册文件：寻址远程文件系统使用以下格式： /sfs/\u003cLocation\u003e:\u003cHostID\u003e Location:代表的是服务网络地方 HostID = hash(public_key || Location) 因此SFS文件系统的名字认证了它的服务，用户可以通过服务提供的公钥来验证，协商一个共享的私钥，保证所有的通信。所有的SFS实例都共享了一个全局的命名空间，这个命名空间的名称分配是加密的，不被任何中心化的body控制。 ","date":"2018-04-04","objectID":"/ipfs/:1:4","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"IPFS 设计 IPFS 是一个分布式文件系统 所用技术：以前 P2P 系统的成功想法，包括 DHT, BitTorrent, Git 和 SFS。 IPFS 是点对点的；没有节点是特权的。 IPFS 协议分为一级负责不同功能的子协议： 身份： 管理节点身份生成和验证 网络： 管理与其他对等体的连接，使用各种底层网络协议。可配置的。 路由： 维护信息以定位特定的对等体和对象。响应本地和远程查询。默认为 DHT, 但可更换。 交换： 一种支持有效块分配的新型块交换协议（BitSwap）。模拟市场，弱化数据复制。贸易策略可替换 对象： 具有链接的内容寻址不可更改对象的 Merkle DAG。用于表示任意数据结构，例如文件层次和通信系统 文件： 由 Git 启发的版本化文件层次结构 命名： 自我认证的可变名称系统 这些子系统不是独立的;它们是集成在一起，互相利用各自的属性。但是，分开描述它们是有用的，从下到上构建协议栈。符号：Go语言中指定了以下数据结构和功能 ","date":"2018-04-04","objectID":"/ipfs/:2:0","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"3.1 身份 节点由 NodeId 标识，这是使用 S / Kademlia 的静态加密难题[1]创建的公钥的密码散列。节点存储其公私钥（用密码加密）。用户可以在每次启动时自由地设置一个“新”节点身份，尽管这会损失积累的网络利益。激励节点保持不变。 type NodeId Multihash type Multihash []byte // 自描述加密哈希摘要 type PublicKey []byte type PrivateKey []byte // 自描述的私钥 type Node struct { NodeId NodeID PubKey PublicKey PriKey PrivateKey } 基于S / Kademlia的IPFS身份生成： difficulty = \u003cinteger parameter\u003e n = Node{} do { n.PubKey, n.PrivKey = PKI.genKeyPair() n.NodeId = hash(n.PubKey) p = count_preceding_zero_bits(hash(n.NodeId)) } while (p \u003c difficulty) 首次连接时，对等体交换公钥，并检查：hash（other.PublicKey）等于other.NodeId。如果没有，则连接被终止 关于加密函数的注意事项： IPFS不是将系统锁定到一组特定的功能选择，而是支持自我描述的值。哈希摘要值以多重哈希格式存储，其包括指定使用的哈希函数的头和以字节为单位的摘要长度。例如 \u003cfunction code\u003e\u003cdigest length\u003e\u003cdigest bytes\u003e 这允许系统 （a）选择最佳功能用例（例如，更强的安全性与更快的性能）， （b）随着功能选择的变化而演变。自描述值允许兼容使用不贩参数选择。 ","date":"2018-04-04","objectID":"/ipfs/:2:1","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"3.2 网络 IPFS节点与数百个其他节点进行定期通信网络中的节点，可能跨越广域网络。IPFS网络堆栈功能： 传输层： IPFS 可以使用任何传输协议，并且最适合 WebRTC DataChannels（用于浏览器连接）或 UTP（LEDBAT [14]） 可靠性：如果底层网络不提供可靠性，IPFS 可使用 UTP（LEDBAT [14]）或SCTP [15]来提供​​可靠性 可连接性：IPFS 还可以使用 ICE NAT 穿墙打洞技术 完整性：可以使用哈希校验和来检查邮件的完整性 可验证性： 可以使用发送者的公钥使用 HMAC 来检查消息的真实性 3.2.1 对等节点寻址注意事项： IPFS 可以使用任何网络；但它不承担对 IP 的获取以及不直接依赖于 IP 层。这允许在覆盖网络中使用 IPFS。 IPFS将地址存储为多层地址，这个多层地址是由字节字符串组成的， 以便于给底层网络使用。多层地址提供了一种方式来表示地址及其协议，可以封装成好解析的格式。例如 # an SCTP/IPv4 connection /ip4/10.20.30.40/sctp/1234/ # an SCTP/IPv4 connection proxied over TCP/IPv4 /ip4/5.6.7.8/tcp/5678/ip4/1.2.3.4/sctp/1234/ ","date":"2018-04-04","objectID":"/ipfs/:2:2","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"3.3 路由 IPFS 节点需要一个路由系统，这个路由系统可用于查找： （a）其他同伴的网络地址 （b）专门用于服务特定对象的对等节点 IPFS 使用基于 S / Kademlia 和 Coral 的 DSHT，在 2.1 节中具体介绍过。在对象大小和使用模式方面， IPFS 类似于 Coral[5] 和 Mainline[16], 因此，IPFS DHT 根据其大小对存储的值进行区分。小的值（等于或小于1KB）直接存储在 DHT 上。对于更大的值，DHT 只存储值索引，这个索引就是一个对等节点的 NodeId, 该对等节点可以提供對该类型的值的具体服务。 DSHT的接口如下： type IPFSRouting interface { FindPeer(node NodeId) // 获取特定NodeId的网络地址。 SetValue(key []bytes, value []bytes) // 往DHT存储一个小的元数据。 GetValue(key []bytes) // 从DHT获取元数据。 ProvideValue(key Multihash) // 声明这个节点可一个提供一个大的数据。 FindValuePeers(key Multihash, min int) // 获取服务于该大数据的节点。 } **注意：**不同的用例将要求基本不同的路由系统（例如广域网中使用DHT，局域网中使用静态HT）。因此，IPFS路由系统可以根据用户的需求替换的。只要使用上面的接口就可以了，系统都能继续正常运行。 ","date":"2018-04-04","objectID":"/ipfs/:2:3","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"3.4 块交换 - BitSwap 协议 IPFS 中的BitSwap协议受到 BitTorrent 的启发，通过对等节点间交换数据块来分发数据的。像BT一样，每个对等节点在下载的同时不断向其他对等节点上传已下载的数据。和 BT 协议不同的是，BitSwap 不局限于一个 torrent 文件中的数据块。BitSwap 协议中存在一个永久的市场。这个市场包括各个节点想要获取的所有块数据。而不管这些块是哪些如.torrent 文件中的一部分。这些快数据可能来自文件系统中完全不相关的文件。 这个市场是由所有的节点组成的。虽然易货系统的概念意味着可以创建虚拟货币，但这将需要一个全局分类账本来跟踪货币的所有权和转移。这可以实施为 BitSwap 策略，并将在未来的论文中探讨。 在基本情况下，BitSwap 节点必须以块的形式彼此提供直接的值。只有当跨节点的块的分布是互补的时候，各取所需的时候，这才会工作的很好。通常情况并非如此，在某些情况下，节点必须为自己的块而工作。 在节点没有其对等节点所需的（或根本没有的）情况下，它会更低的优先级去寻找对等节点想要的块。这会激励节点去缓存和传播稀有片段， 即使节点对这些片段不感兴趣。 个从理解这么做的原因可以激励数据可以存在更多的节点上， 3.4.1 - BITSWAP 信用 这个协议必须带有激励机制， 去激励节点去seed 其他节点所需要的块，而它们本身是不需要这些块的。 因此， BitSwap 的节点很积极去给对端节点发送块，期待获得报酬。但必须防止水蛭攻击（空负载节点从不共享块），一个简单的类似信用的系统解决了这些问题： 对等节点间会追踪他们的平衡（通过字节认证的方式） 随着债务增加而概率降低，对等者概率的向债务人发送块。 注意，如果节点决定不发送到对等体，节点随后忽略对等体的 ignore_cooldown 超时。 这样可以防止发送者尝试多次发送（洪水攻击） （BitSwap 默认是 10 秒） 3.4.2 BITSWAP 的策略 BitSwap 对等节点采用很多不同的策略，这些策略对整个数据块的交换执行力产生了不同的巨大影响。在 BT 中， 标准策略是明确规定的（tit-for-tat），其他不同的策略也已经被实施，从 BitTyrant [8]（尽可能分享）到 BitThief [8]（利用一个漏洞，从不共享），到 PropShare [8]（按比例分享）。BitSwap 对等体可以类似地实现一系列的策略（良好和恶意）。对于功能的选择，应该瞄准： 为整个交易和节点最大化交易能力 为了防止空负载节点利用和损害交易 高效抵制未知策略 对可信任的对等节点更宽容 探索这些策略的空白是未来的事情。在实践中使用的一个选择性功能是sigmoid，根据负债比例进行缩放： 让负债比例在一个节点和它对等节点之间： r = bytes_sent / bytes_recv + 1 根据r，发送到负债节点的概率为: P(send | r ) = 1 − ( 1/ ( 1 + exp(6 − 3r) ) ) 正如你看到的图片1，当节点负债比例超过节点已建立信贷的两倍，发送到负债节点的概率就会急速下降。 这里是不是可以理解为因为负债太高，大家就都不带你玩了 图片1 当r增加时发送的概率 负债比是信任的衡量标准：对于之前成功的互换过很多数据的节点会宽容债务，而对不信任不了解的节点会严格很多。这个 (a)给与那些创造很多节点的攻击者（ sybill 攻击）一个障碍。 (b)保护了之前成功交易节点之间的关系，即使这个节点暂时无法提供数据。 ©最终阻塞那些关系已经恶化的节点之间的通信，直到他们被再次证明。 3.4.3 BITSWAP 账本 BitSwap 节点保存了一个记录与所有其他节点之间交易的账本。这个可以让节点追踪历史记录以及避免被篡改。当激活了一个链接，BitSwap 节点就会互换它们的账本信息。如果这些账本信息并不完全相同，分类账本将会重新初始化， 那些应计信贷和债务会丢失。 恶意节点会有意去失去“这些“账本， 从而期望清除自己的债务。节点是不太可能在失去了应计信托的情况下还能累积足够的债务去授权认证。伙伴节点可以自由的将其视为不当行为， 拒绝交易。 我可以理解为账本在同步，有假账产生时，其它节点视为不当行为，拒绝交易吗？ type Ledger struct { owner NodeId partner NodeId bytes_sent int bytes_recv int timestamp Timestamp } 3.4.4 BITSWAP 详解 BitSwap 节点有以下简单的协议。 // Additional state kept type BitSwap struct { ledgers map[NodeId]Ledger // Ledgers known to this node, inc inactive active map[NodeId]Peer // currently open connections to other nodes need_list []Multihash // checksums of blocks this node needs have_list []Multihash // checksums of blocks this node has } type Peer struct { nodeid NodeId ledger Ledger // Ledger between the node and this peer last_seen Timestamp // timestamp of last received message want_list []Multihash // checksums of all blocks wanted by peer // includes blocks wanted by peer's peers } // Protocol interface: interface Peer { open (nodeid : NodeId, ledger : Ledger); send_want_list (want_list : WantList); send_block(block: Block) -\u003e (complete:Bool); close(final: Bool); } 对等连接的生命周期草图： Open:对等节点间发送 ledgers 直到他们同意 Sending: 对等节点间交换 want_lists 和 blocks。 Close: 对等节点断开链接。 Ignored: （特殊）对等体被忽略（等待时间的超时）如果节点采用防止发送策略 - Peer.open(NodeId, Ledger). 当发生链接的时候，节点会初始化链接的账本，要么保存一个份链接过去的账本，要么创建一个新的被清零的账本。然后，发送一个携带账本的open信息给对等节点。 接收到一个 open 信息之后，对等节点可以选择是否接受此链接。如果，根据接收者的账本，发送者是一个不可信的代理（传输低于零或者有很大的未偿还的债务），接收者可能会选择忽略这个请求。忽略请求是 ignore_cooldown 超时来概率性实现的，为了让错误能够有时间改正和攻击者被挫败。 如果链接成功，接收者用本地账本来初始化一个 Peer 对象以及设置 last_seen 时间戳。然后，它会将接受到的账本与自己的账本进行比较。如果两个账本完全一样，那么这个链接就被 Open，如果账本并不完全一致，那么此节点会创建一个新的被清零的账本并且会发送此账本。 - Peer.send_want_list(WantList) 当链接已经 Open 的时候，节点会 广发 它们的 want_list 给所有已经链接的对等节点。这个是在 (a)open链接后 (b)随机间歇超时后 ©want_list改变后 (d)接收到一个新的块之后完成的。 当接收到一个 want_list 之后，节点会存储它。然后，会检查自己是否拥有任何它想要的块。如果有，会根据上面提到的 BitSwap 策略来将 want_list 所需要的块发送出去。 - Peer.send_block(Block) 发送一个块是直接了当的。节点只是传输数据块。当接收到了所有数据的时候，接收者会计算多重 hash 校验和来验证它是否是自己所需数据，然后发送确认信息。 在完成一个正确的块传输之后，接受者会将此块从 need_list 一到 have_list,最后接收者和发送者都会更新它们的账本来反映出传输的额外数据字节数。 如果一个传输验证失败了，发送者要么会出故障要么会攻击接收者，接收者可以选择拒绝后面的交易。注意，BitSwap 是期望能够在一个可靠的传输通道上进行操作的，所以传输错误（可能会引起一个对诚实发送者错误的惩罚）是期望在数据发送给 BitSwap 之前能够被捕捉到。 - Peer.close(Bool) 传给 close 最后的一个参数，代表 close 链接是否是发送者的意愿。如果参数值为 false,接收者可能会立即重新 open 链接，这避免链过早的 close 链接。 一个对等节点 close 链接发生在下面两种情况下： silence_wait 超时已经过期，并且没有接收到来自于对等节点的任何信息（BitSwap 默认使用 30 秒），节点会发送 Peer.close(false)。 在节点退出和 BitSwap 关闭的时候，节点会发送","date":"2018-04-04","objectID":"/ipfs/:2:4","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"3.5 Merkle DAG 对象 DHT 和 BitSwap 允许 IPFS 构造一个庞大的点对点系统用来快速稳定的分发和存储。最主要的是，IPFS 建造了一个 Merkle DAG,一个无回路有向图（有向无环图），对象之间的 links 都是 hash 加密嵌入在源目标中。这是 Git 数据结构的一种推广。Merkle DAGS 给 IPFS 提供了很多有用的属性，包括： 1.内容可寻址：所有内容都是被多重 hash 校验和来唯一识别的，包括 links。 2.防止篡改：所有的内容都用它的校验和来验证。如果数据被篡改或损坏，IPFS 会检测到。 3.重复数据删除：所有的对象都拥有相同的内容并只存储一次。这对于索引对象非常有用，比如 git 的 tree 和 commits，或者数据的公共部分。 IPFS对象的格式是： type IPFSLink struct { Name string // 此link的别名 Hash Multihash // 目标的加密hash Size int // 目标总大小 } type IPFSObject struct { links []IPFSLink //links数组 data []byte //不透明内容数据 } IPFS Merkle DAG是存储数据非常灵活的一种方式。只要求对象引用是(a）内容可寻址的，(b)用上面的格式编码。IPFS允许应用完全的掌控数据域；应用可以使用任何自定义格式的数据，即使数据IPFS都无法理解。单独的内部对象link表允许IPFS做： 用对象的形式列出所有对象引用，例如 ipfs ls /XLZ1625Jjn7SubMDgEyeaynFuR84ginqvzb XLYkgq61DYaQ8NhkcqyU7rLcnSa7dSHQ16x 189458 less XLHBNmRQ5sJJrdMPuu48pzeyTtRo39tNDR5 19441 script XLF4hwVHsVuZ78FZK6fozf8Jj9WEURMbCX4 5286 template \u003cobject multihash\u003e \u003cobject size\u003e \u003clink name\u003e 解决字符串路经查找，例如 foo/bar/baz。给出一个对象，IPFS 会解析第一个路经成分进行 hash 放入到对象的 link 表中，再获取路径的第二个组成部分，一直如此重复下去。因此，任何数据格式的字符串路经都可以在 Merkle DAG 中使用。 *递归性的解决所有对象引用： ipfs refs --recursive /XLZ1625Jjn7SubMDgEyeaynFuR84ginqvzb XLLxhdgJcXzLbtsLRL1twCHA2NrURp4H38s XLYkgq61DYaQ8NhkcqyU7rLcnSa7dSHQ16x XLHBNmRQ5sJJrdMPuu48pzeyTtRo39tNDR5 XLWVQDqxo9Km9zLyquoC9gAP8CL1gWnHZ7z 原始数据结构公共 link 结构是 IPFS 构建任意数据结构的必要组成部分。可以很容易看出 Git 的对象模型是如何套用 DAG 的。一些其他潜在的数据结构: (a) 键值存储 (b) 传统关系型数据 (c) 数据三倍存储 (d) 文档发布系统 (e) 通信平台 (f) 加密货币区块。 这些系统都可以套用 IPFS Merkle DAG，这使这些系统更复杂的应用可以使用 IPFS 作为传输协议。 3.5.1 路径 IPFS 对象可以遍历一个字符串路经。路经格式与传统 UNIX 文件系统以及 Web 一致。Merkle DAG 的 links 使遍历变得很容易。全称路经在 IPFS 中的格式是： *# 格式 /ipfs/\u003chash-of-object\u003e/\u003cname-path-to-object\u003e *# 例子 /ipfs/XLYkgq61DYaQ8NhkcqyU7rLcnSa7dSHQ16x/foo.txt /ipfs前缀允许只要在挂载点不冲突(挂载点名称当然是可配置的)的情况下挂载到一个已存在的系统上。第二个路经组成部分(第一个是IPFS)是一个对象的hash。通常都是这种情况，因为没有全局的根。一个根对象可能会有一个不可能完成的任务，就是在分布式环境(可能还断开链接)中处理百万对象的一致性。因此，我们用地址可寻址来模拟根。通过的hash所有的对象都是可访问的。这意思是说，给一个路经对象/bar/baz，最后一个对象可以可以被所有的访问的： /ipfs/\u003chash-of-foo\u003e/bar/baz /ipfs/\u003chash-of-bar\u003e/baz /ipfs/\u003chash-of-baz\u003e 3.5.2 本地对象 IPFS 客户端需要一个本地存储器，一个外部系统可以为 IPFS 管理的对象存储以及检索本地原始数据。存储器的类型根据节点使用案例不同而不同。在大多数情况下，这个存储器只是硬盘空间的一部分（不是被本地的文件系统使用键值存储如 leveldb 来管理，就是直接被 IPFS 客户端管理），在其他的情况下，例如非持久性缓存，存储器就是 RAM 的一部分。 最终，所有的块在 IPFS 中都是能够获取得到的，块都存储在了一些节点的本地存储器中。当用户请求一个对象时，这个对象会被查找到并下载下来存储到本地，至少也是暂时的存储在本地。这为一些可配置时间量提供了快速的查找。 这一段主要讲了本地对象的存储：1.持久性：硬盘空间的一部分；2.非持久性：RAM 3.5.3 对象锁定 希望确保特定对象生存的节点可以锁定此对象。这保证此特定对象被保存在了节点的本地存储器上。也可以递归的进行锁定所有相关的派生对象。这使所有被指定的对象都保存在本地存储器上。这对长久保存文件特别有用，包括引用。这也同样让 IPFS 成为一个 links 是永久的 Web，且对象可以确保其他被指定对象的生存。 3.5.4 发布对象 IPFS 是全球分布的。它设计为允许成千上万的用户文件可以共同的存在的。DHT 使用内容哈希寻址技术，使发布对象是公平的，安全的，完全分布式的。任何人都可以发布对象，只需要将对象的 key 加入到 DHT 中，并且以对象是对等节点的方式加入进去，然后把路径给其他的用户。要注意的是，对象本质上是不可改变的，就像在 Git 中一样。新版本的哈希值不同，因此是新对象。跟踪版本则是额外版本对象的工作。 3.5.5 对象级别的加密 IPFS 是具备可以处理对象级别加密操作的。一个已加密的或者已签名的对象包装在一个特殊的框架里，此框架允许加密和验证原始字节。 type EncryptedObject struct { Object []bytes // 已加密的原始对象数据 Tag []bytes // 可选择的加密标识 type SignedObject struct { Object []bytes // 已签名的原始对象数据 Signature []bytes // HMAC签名 PublicKey []multihash // 多重哈希身份键值 } 加密操作改变了对象的哈希值，定义一个不同的新的对象。IPFS 自动的验证签名以及使用用户指定的钥匙链解密数据。加密数据的 links 也同样的被保护着，没有解密秘钥就无法遍历对象。也存在着一种现象，可能父对象使用了一个秘钥进行了加密，而子对象使用了另一个秘钥进行加密或者根本没有加密。这可以保证links共享对象安全。 可以通过加密操作，定义一个新的对象。可以自动验证签名，可以解密；links 也被保护着 ","date":"2018-04-04","objectID":"/ipfs/:2:5","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"3.6 文件 IPFS 在 Merkle DAG 上还为模型化版本文件系统定义了一组对象。这个对象模型与 Git 比较相似： Block：一个可变大小的数据块 List：块或者其他链表的集合 Tree：块，链表，或者其他树的集合 Commit：树在版本历史记录中的一个快照 我原本希望使用与Git对象格式一致的模型，但那就必须要分开来引进在分布式文件系统中有用的某些特征，如 （a）快速大小查找（总字节大小已经加入到对象中） （b）大文件的重复删除（添加到 list 对象） （c）commits 嵌入到 trees 中。不过，IPFS 文件对象与 Git 还是非常相近的，两者之间进行交流都是有可能的。而且，Git 的一个系列的对象可以被引进过来转换都不会丢失任何的信息。（UNIX 文件权限等等）。 标记： 下面的文件对象格式使用 JSON。注意，虽然 IPFS 包含了 JSON 的互相转换，但是文件对象的结构体还是使用 protobufs 的二进制编码。 3.6.1 文件对象：BLOB blob 对象代表一个文件且包含一个可寻址的数据单元，IPFS 的 blobs 就像 Git 的 blobs 或者文件系统数据块。它们存储用户的数据。需要留意的是 IPFS 文件可以使用 lists 或者 blobs 来表示。Blobs 没有 links。 { \"data\": \"some data here\", // blobs无links } 3.6.2 文件对象：LIST List 对象代表着由几个 IPFS 的 blobs 连接成的大文件或者重复数据删除文件。Lists 包含着 有序的 blob 序列 或 list 对象。从某种程度上而言，IPFS 的 list 函数就像一个间接块的文件系统。由于 lists 可以包含其他的 lists，那么包含 linked 的链表和平衡树的拓扑结构是有可能的。有向图中相同的节点出现在多个不同地方允许在文件中重复数据删除。当然，循环是不可以的，因为是被哈希寻址强制实行的。 { \"data\": [\"blob\", \"list\", \"blob\"], //lists有一个对象类型的数组作为数据 \"links\": [ { \"hash\": \"XLYkgq61DYaQ8NhkcqyU7rLcnSa7dSHQ16x\", \"size\": 189458 }, { \"hash\": \"XLHBNmRQ5sJJrdMPuu48pzeyTtRo39tNDR5\", \"size\": 19441 }, { \"hash\": \"XLWVQDqxo9Km9zLyquoC9gAP8CL1gWnHZ7z\", \"size\": 5286 } //在links中lists是没有名字的 ] } 3.6.3 文件对象：TREE IPFS 中的 tree 对象与 Git 中相似，它代表着一个目录，一个名字到哈希值的映射。哈希值则表示着 blobs，lists，其他的 trees，或者 commits。注意，传统路径的命名早已经被 Merkle DAG 实现了。 { \"data\": [\"blob\", \"list\", \"blob\"],//trees有一个对象类型的数组作为数据 \"links\": [ { \"hash\": \"XLYkgq61DYaQ8NhkcqyU7rLcnSa7dSHQ16x\", \"name\": \"less\", \"size\": 189458 }, { \"hash\": \"XLHBNmRQ5sJJrdMPuu48pzeyTtRo39tNDR5\", \"name\": \"script\", \"size\": 19441 }, { \"hash\": \"XLWVQDqxo9Km9zLyquoC9gAP8CL1gWnHZ7z\", \"name\": \"template\", \"size\": 5286 }//trees是有名字的 ] } 3.6.4 文件对象：COMMIT IPFS 中的 commit 对象代表任何对象在版本历史记录中的一个快照。与 Git 中类似，但是它能够表示任何类型的对象。它同样 link 着发起对象。 3.6.5 版本控制 Commit 对象代表着一个对象在历史版本中的一个特定快照。在两个不同的 commit 中比较对象（和子对象）可以找出两个不同版本文件系统的区别。只要 commit 和它所有子对象的引用是能够被访问的，所有之前的版本是可获取的，所有文件系统改变的全部历史是可访问的，这就与 Merkle DAG 对象模型脱离开来了。 Git版本控制工具的所有功能对于IPFS的用户是可用的。对象模型不完全一致，但也是可兼容的。这可能 （a）构建一个 Git 工具版本改造成使用 IPFS 对象图 （b）构建一个挂载 FUSE 文件系统，挂载一个 IPFS 的 tree 作为 Git 的仓库，把 Git 文件系统的读/写转换为 IPFS 的格式。 3.6.6 文件系统路径 如我们在 Merkle DAG 中看到的一样，IPFS 对象可以使用字符串路径 API 来遍历。IPFS 文件对象是特意设计的，为了让挂载 IPFS 到 UNIX 文件系统更加简单。文件对象限制 trees 没有数据，为了使它们可以表示目录。Commits 可以以代表目录的形式出现，也可以完全的隐藏在文件系统中。 没有看懂 3.6.7 将文件分隔成 LISTS 和 BLOBS 版本控制和分发大文件其中一个最主要的挑战是：找到一个正确的方法来将它们分隔成独立的块。与其认为 IPFS 可以为每个不同类型的文件提供正确的分隔方法，不如说 IPFS 提供了以下的几个可选选择： 就像在 LIBFS 中一样使用 Rabin Fingerprints 来选择一个比较合适的块边界。 使用 rsync rolling-checksum 算法，来检测块在版本之间的改变。 允许用户指定专为特定文件而调整的’快分隔’函数。 3.6.8 路径查找性能 基于路径的访问需要遍历对象图。获取每个对象要求在 DHT 中查找它们的 key，连接到对等节点，然后获取它的块。这造成相当大的开销，特别是查找的路径由很多子路径组成时。下面的方法可以减缓开销： tree 缓存：由于所有的对象都是哈希寻址的，它们可以被无限的缓存。另外，trees 一般比较小，所以比起 blobs，IPFS 会优先缓存 trees。 flattened trees 对于任何 tree，一个特殊的 flattened tree 可以构建一个链表，所有对象都可以从这个tree中访问得到。在 flattened tree 中名字就是一个从原始 tree 分离的路径，用斜线分隔。 例如，对于上面的ttt111的flattened tree如下： { \"data\": [\"tree\", \"blob\", \"tree\", \"list\", \"blob\" \"blob\"], \"links\": [ { \"hash\": \"\u003cttt222-hash\u003e\", \"size\": 1234 \"name\": \"ttt222-name\" }, { \"hash\": \"\u003cbbb111-hash\u003e\", \"size\": 123, \"name\": \"ttt222-name/bbb111-name\" }, { \"hash\": \"\u003cttt333-hash\u003e\", \"size\": 3456, \"name\": \"ttt333-name\" }, { \"hash\": \"\u003clll111-hash\u003e\", \"size\": 587, \"name\": \"ttt333-name/lll111-name\"}, { \"hash\": \"\u003cbbb222-hash\u003e\", \"size\": 22, \"name\": \"ttt333-name/lll111-name/bbb222-name\" }, { \"hash\": \"\u003cbbb222-hash\u003e\", \"size\": 22 \"name\": \"bbb222-name\" } ] } ","date":"2018-04-04","objectID":"/ipfs/:2:6","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"3.7 IPNS: 命名以及易变状态 目前为止，IPFS 桟形成了一个对等块交换组成一个内容可寻址的 DAG 对象。这提供了发布和获取不可改变的对象。这甚至可以跟踪这些对象的版本历史记录。但是，这里有一个关键成分遗漏了：易变的命名。没有这个，发送 IPFS 的 links，所有新内容的通信肯定都会有所偏差。现在所需就是能有某些方法可以获取相同路径的的易变状态。 这值得详述原因 – 如果最终易变数据是必须的 – 我们费了很大的力气构建了一个不可改变的 Merkle DAG。就当做 IPFS 脱离了 Merkle DAG 的特征：对象可以 （a）通过哈希值可以获取 （b）完整的检查 （c）link 其他的对象 （d）无限缓存。从某种意义上说： 对象就是永恒的 这些就是一个高性能分布式系统的关键特征，在此系统上跨网络 links 之间移动文件是非常昂贵的。对象内容可寻址构建了一个具有以下特点的 Web， (a)优秀的宽带优化 (b)不受信任的内容服务 ©永恒的 links (d)能够永久备（份）任何对象以及它的引用。 不可变的内容可寻址对象和命名的 Merkle DAG， 可变指针指向 Merkle DAG，实例化了一个出现在很多成功分布式系统中的二分法。这些系统包括 Git 的版本控制系统，使用不可变的对象和可变的引用；还有 UNIX 分布式的继承者 Plan9 文件系统，使用可变的 Fossil 和不可变的 Venti。LBFS 同样使用可变的索引以及不可变的块。 3.7.1 自我认证名称 使用 SFS[12,11] 中的命名方案，给我们提供了一种可以构建自我认证名称的方法， 在一个加密指定的全局命名空间中，这是可变的。IPFS的方案如下： 回想一下在 IPFS 中：NodeId = hash(node.PubKey) 我们给每个用户分配一个可变的命名空间，在此路径下：/ipns/ 一个用户可以在此路径下发布一个用自己私钥签名的对象，比如说：/ipns/XLF2ipQ4jD3UdeX5xp1KBgeHRhemUtaA8Vm/ 当其他用户获取对象时，他们可以检测签名是否与公钥和 NodeID 匹配。这个验证了用户发布对象的真实性，达到了可变状态的获取。 注意下面的细节： IPNS(InterPlanetary的命名空间)分开前缀是在可变和不可变的路径之间建立一个很容易辨认的区别，为了程序也为了人类阅读的便利 因为这不是一个内容可寻址的对象，所以发布它就要依靠 IPFS 中的唯一的可变状态分配制度，路由系统。过程是 (a)首先把此对象做一个常规的不可变 IPFS 的对象来发布 (b)将此对象的哈希值作为元数据的值发布到路由系统上： routing.setValue(NodeId, ) 发布的对象中任何 links 在命令空间中充当子名称： /ipns/XLF2ipQ4jD3UdeX5xp1KBgeHRhemUtaA8Vm/ /ipns/XLF2ipQ4jD3UdeX5xp1KBgeHRhemUtaA8Vm/docs /ipns/XLF2ipQ4jD3UdeX5xp1KBgeHRhemUtaA8Vm/docs/ipfs 一般建议发布一个 commit 对象或者其他对象的时候，要使用历史版本记录，因为这样就用户就可以找到之前使用过的名字。不过由于这并不总是需要的，所以留个用户自己选择。 注意： 当用户发布一个对象的时候，他不能使用相同的方式来发布对象 3.7.2 人类友好名称 IPNS 的确是一个分配和在分配名称的好方法，但是对用户却不是十分的友好，因为它使用很长的哈希值作为名称，众所周知这样的名称很难被记住。IPNS 足够应付 URLs，但对于很多线下的传输工作就没有这么好用了。因此，IPFS 使用下面的技术来增加 IPNS 的用户友好度。 对等节点 Links 被 SFS 所鼓舞，用户可以直接将其他用户的对象 link 到自己的对象上（命令空间，家目录等等）。这有一个好处就是创建了一个可信任的 Web（也支持老的真实性认证模型）： # Alice links 到Bob上 ipfs link /\u003calice-pk-hash\u003e/friends/bob /\u003cbob-pk-hash\u003e # Eve links 到Alice上 ipfs link /\u003ceve-pk-hash/friends/alice /\u003calice-pk-hash\u003e # Eve 也可以访问Bob /\u003ceve-pk-hash/friends/alice/friends/bob # 访问Verisign 认证域 /\u003cverisign-pk-hash\u003e/foo.com DNS TXT IPNS 记录 如果 /ipns/ 是一个有效的域名称，IPFS 会在 DNS TXT 记录中查找关键的 ipns。IPFS 会将查找到的值翻译为一个对象的哈希值或者另一个 ipns 的路径： # DNS TXT 记录 ipfs.benet.ai. TXT \"ipfs=XLF2ipQ4jD3U ...\" # 表现为符号链接 ln -s /ipns/XLF2ipQ4jD3U /ipns/fs.benet.ai Proquint 可读的标识符 总是会有将二进制编码翻译成可读文件的方法。IPNS 则支持 Proquint[?].。如下： # proquint语句 /ipns/dahih-dolij-sozuk-vosah-luvar-fuluh # 分解为相应的下面形式 /ipns/KhAwNprxYVxKqpDZ 缩短名称服务 会涌现出很多服务器提供缩短名称的服务，向用户提供他们的命名空间。就像我们现在看到的 DNS 和 Web 的 URLs： # 用户可以从下面获取一个link /ipns/shorten.er/foobar # 然后放到自己的命名空间 /ipns/XLF2ipQ4jD3UdeX5xp1KBgeHRhemUtaA8Vm ","date":"2018-04-04","objectID":"/ipfs/:2:7","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"3.8 使用IPFS IPFS 设计为可以使用多种不同的方法来使用的，下面就是一些我将会继续追求的使用方式： 1.作为一个挂载的全局文件系统，挂载在/ipfs和/ipns下 2.作为一个挂载的个人同步文件夹，自动的进行版本管理，发布，以及备份任何的写入 3.作为一个加密的文件或者数据共享系统 4.作为所有软件的版本包管理者 5.作为虚拟机器的根文件系统 6.作为VM的启动文件系统 (在管理程序下) 7.作为一个数据库：应用可以直接将数据写入Merkle DAG数据模型中，获取所有的版本，缓冲，以及IPFS提供的分配 8.作为一个linked（和加密的）通信平台 9.作为一个为大文件的完整性检查CDN（不使用SSL的情况下） 10.作为一个加密的CDN 11.在网页上，作为一个web CDN 12.作为一个links永远存在新的永恒的Web IPFS实现的目标： (a) 一个 IPFS 库可以导出到你自己应用中使用 (b) 命令行工具可以直接操作对象 © 使用FUSE[?]或者内核的模型挂载文件系统 ","date":"2018-04-04","objectID":"/ipfs/:2:8","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"4. 未来 IPFS的思想是几十年成功的分布式系统的探索和开源的产物。IPFS 综合了很多迄今为止很成功的系统中优秀的思想。除了 BitSwap 新协议之外，IPFS 最大的特色就是系统的耦合以及设计的综合性。 IPFS 是去中心化网络基础设施的一个野心设想，很多不同类型的应用都可以建立在 IPFS 上。最低限度，它可以用来作为一个全局的，挂载性，版本控制文件系统和命名空间，或者作为下一代的文件共享系统。而最好的情况是，IPFS 可以让 Web 升级一个层次，当发布一个有价值的信息时，任何感兴趣的人都可以进行发布而不会强迫性的必须只允许发布机构进行发布，用户可以信任信息的内容，信不信任信息的发送者都是无关紧要的，还有一个特点就是，一些重要但很老的文件也不会丢失。IPFS 期待着带我们进入到一个永恒 Wdb 的世界。 ","date":"2018-04-04","objectID":"/ipfs/:2:9","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"5. 感谢 IPFS 是一个很多很棒的主意以及系统的综合体。没有站在巨人的肩膀上，IPFS 也不可能敢于有一个这么有野心的目标。个人感谢参与这些主意长期讨论的人：David Dalrymple, Joe Zimmerman, and Ali Yahya，特别是：揭开Merkle DAG的总体架构(David, Joe),滚动哈希阻塞(David), s/kademlia sybill 保护(David, Ali)，特别感谢David Mazieres,为他之前非常聪明的主意。 ","date":"2018-04-04","objectID":"/ipfs/:2:10","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"6. 引用 [1].I. Baumgart and S. Mies. S/kademlia:一个安全的基于秘钥路由的可行方法。2007年国际会议，第2卷，1-8页，在《并发和分布式系统》中。IEEE，2007年。 [2].I. BitTorrent.Bittorrent和Attorrent软件超过1亿5000万用户里程碑，Jan。2012 [3].B. Cohen.激励机制在bittorrent中建立了健壮性。在《对等系统经济研讨会》中，第6卷，68-72页，2003年。 [4].J. Dean and S. Ghemawat. Leveldb - 一个快速和轻量级键值存储数据库，谷歌提供，2011年。 [5].M. J. Freedman, E. Freudenthal, and D. Mazieres. Coral民主内容发布。在NSDI中，第4卷，18-18页，2004年。 [6].J. H. Howard, M. L. Kazar, S. G. Menees, D. A,Nichols, M. Satyanarayanan, R. N. Sidebotham, 以及M. J. West.分布式文件系统的规模和性能。“ACM 电脑系统上的交易 （TOCS）” 6(1):51-81, 1988年 ","date":"2018-04-04","objectID":"/ipfs/:2:11","tags":["blc","IPFS"],"title":"IPFS","uri":"/ipfs/"},{"categories":["区块链"],"content":"学习 Hyperledger Fabric 的相关网址","date":"2018-03-29","objectID":"/hyperledger-fabric-%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3/","tags":["blc","hyperledger"],"title":"Hyperledger Fabric 相关文档","uri":"/hyperledger-fabric-%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3/"},{"categories":["区块链"],"content":"Hyperledger Fabric 相关文档 搬来搬去，还是想有自己的地方，于是到这里来了 ","date":"2018-03-29","objectID":"/hyperledger-fabric-%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3/:0:0","tags":["blc","hyperledger"],"title":"Hyperledger Fabric 相关文档","uri":"/hyperledger-fabric-%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3/"},{"categories":["区块链"],"content":"学习网址 区块链和HyperLedger开源技术讲堂 最好的入门视频教程 hyperledger-fabric 官方文档 需要通读 hyperledger 官网 GitHub hyperledger/fabric GitHub hyperledger/fabric-sdk-node GitHub hyperledger/fabric-sdk-java fabric-sdk-go Fabric 1.0 源码分析 搜索疑难问题链接 fabric 代码库 hypeledger 开发进展 java智能合约部署与开发 api网址 Overview - Hyperledger Fabric IBM Blockchain hyperledger/fabric chat.hyperledger.org Gerrit Code Review 00-Empty View [Jenkins] 部分翻译文章 网络部署 Fabric CA 用户指南 新 ","date":"2018-03-29","objectID":"/hyperledger-fabric-%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3/:0:1","tags":["blc","hyperledger"],"title":"Hyperledger Fabric 相关文档","uri":"/hyperledger-fabric-%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3/"},{"categories":["区块链"],"content":"其他网址 1.DEV ENV Setup end-to-end.rst fabric1.0快速部署 Fabric 的示意图片汇总 Fabric 开发环境搭建 Hyperledger 智能合约 Hello World 示例程序 本文介绍了在IBM Bluemix上部署Hyperledger应用的基本过程 开发环境入门 区块链的相关名词解释 区块链基础设施的架构 HyperLedger Fabric协议规范 下一代Consensus 架构提案 Hyperledger Ordering Service ","date":"2018-03-29","objectID":"/hyperledger-fabric-%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3/:0:2","tags":["blc","hyperledger"],"title":"Hyperledger Fabric 相关文档","uri":"/hyperledger-fabric-%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3/"},{"categories":["区块链"],"content":"图书 Node.js开发加密货币 区块链技术指南，内容非常丰富 Go 语言学习 Docker Practice The Go Programming Language》中文版本 Node入门 Docker 入门到实践 hyperLedger 结构分析 《Bitcoin: A Peer-to-Peer Electronic Cash System》 中本聪，作为比特币系统的设计者和创造者，TA 对于比特币系统最初的设计思路都在这短短的一篇论文中。无论何时去看这边论文，你都会或多或少有所收获，非常值得阅读。一共就 9 页，可以尝试着读完 《Mastering Bitcoin》 这本书毋庸置疑的将成为你应该阅读的第一本比特币技术类的数据，它由浅入深将比特币从钱包的 cli 命令，到协议分析，到钱包的类型一一做了介绍，并且还会在必要的部分提供一些代码，便于读者去理解比特币的运作方式。这应该是我第二次正式的以文字的方式推荐此书了。并且本书除了英文版本，还有社区维护的简体中文版本，这对于国内的开发者来说是一个福音。（当然，我还是推荐你再看一遍英文版本） ","date":"2018-03-29","objectID":"/hyperledger-fabric-%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3/:0:3","tags":["blc","hyperledger"],"title":"Hyperledger Fabric 相关文档","uri":"/hyperledger-fabric-%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3/"},{"categories":["区块链"],"content":"白皮书 亿书白皮书 超级账本Hyperledger白皮书（中文版） 小蚁白皮书 http://wutongtree.github.io/NXT白皮书中文译本.pdf ","date":"2018-03-29","objectID":"/hyperledger-fabric-%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3/:0:4","tags":["blc","hyperledger"],"title":"Hyperledger Fabric 相关文档","uri":"/hyperledger-fabric-%E7%9B%B8%E5%85%B3%E6%96%87%E6%A1%A3/"},{"categories":["区块链"],"content":"一些区块链项目的白皮书","date":"2018-03-29","objectID":"/whitepaper/","tags":["blc","whitepaper"],"title":"加密数字货币白皮书","uri":"/whitepaper/"},{"categories":["区块链"],"content":"加密数字货币白皮书 POWER LEDGER 中文 POWER LEDGER 英文 比特币白皮书 以太坊 量子链 零币 ICOCION 比特股 比原链 瑞资链 点点币 元宝币 质数币 未来币 瑞波币 小蚁 达世币 BAT 彩色币 以太经典 印链 元界 元界数字身份认证 ZENGOLD 房地产代币 EOS DHG Starta iEx 公*宝 UG链：去中⼼化游戏账户系统 玄链：一个基于区块链技术的颠覆式小说原创阅读平台 域链 联合币 Achain ATLANT 平台 ","date":"2018-03-29","objectID":"/whitepaper/:0:0","tags":["blc","whitepaper"],"title":"加密数字货币白皮书","uri":"/whitepaper/"},{"categories":["博客"],"content":"关于我的博客平台的选择","date":"2018-03-24","objectID":"/about-blog/","tags":["blog","hugo"],"title":"About Blog","uri":"/about-blog/"},{"categories":["博客"],"content":"Hello Hugo ","date":"2018-03-24","objectID":"/about-blog/:0:0","tags":["blog","hugo"],"title":"About Blog","uri":"/about-blog/"},{"categories":["博客"],"content":"Hello Hugo 折腾了一周多的时间，现在终于可以用了。暂时没用 wercker，官方文档说得也是比较明白。 最开始也是在自己的 VPS 上用 wordpress 上搞的。整体也整理好了。当我想换个主题时就发现很麻烦，然后就开始找有没有一种搭建个人博客的方式是更简单，更便于管理和修改主题的。先是找到了 Jekyll, 然后就找到了 Hexo 和 Hugo，最后决定定居在 Hugo。 Jekyll 是最早开始流行的静态网站构建工具，使用 Ruby 语言开发，开源已有 10 个年头了，是 Github Pages 默认的静态网站构建工具。当前互联网上有大量基于 Jekyll 构建的静态网站，包括现在流行的开源容器编排高度引擎 kubernetes 的官网。 三款静态网站构建工具的简要对比： 工具名称 开发语言 构建效率 典型用例 特点 Jekyll Ruby 比较慢 Github Pages 默认的静态网站构建工具。 历史悠久，开源已 10 年，模板和插件众多，但是构建 速度慢 Hexo Node.js 一般 个人博客、产品展示 页面酷炫，前端开发者用户居多 Hugo Golang 极快 个人博客、产品展示 Golang 大神 spf13 开发，开源已 5 年，升级活跃，构建速度极快，后端开发者用户居多 以上工具都可以将 Markdown 内容转换为静态页面。 后面还会再添加一些新的配置。 参考 静态网站构建工具简介 ","date":"2018-03-24","objectID":"/about-blog/:0:1","tags":["blog","hugo"],"title":"About Blog","uri":"/about-blog/"}]